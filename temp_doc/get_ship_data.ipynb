{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a354ef66",
      "metadata": {},
      "source": [
        "# Get Echo Data from the Pacific Hake Survey\n",
        "\n",
        "This notebook uses EK60 echosounder data collected during  [the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey (\u2018Pacific Hake Survey\u2019)](https://www.fisheries.noaa.gov/west-coast/science-data/joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-survey)  to illustrate a common workflow for data conversion, calibration and visualization using echopype and echoshader.\n",
        "\n",
        "Ten days of cloud-hosted .raw data files are accessed by echopype directly from an  `Amazon  Web  Services  (AWS)  S3`  \u201cbucket\u201d maintained by the NOAA NCEI Water-Column Sonar Data Archive. The total data used are 365 .raw files at approximately 25 MB each (1 Hz pinging rate from first light to dusk), corresponding to approximately 40 GB. With echopype, each file is converted to a standardized representation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5640f290",
      "metadata": {},
      "source": [
        "## Establish `AWS S3` file system connection and Process S3-hosted raw files with  `echopype`\n",
        "\n",
        "We encourage importing  `echopype`  as `ep`  for consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828652cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import itertools as it\n",
        "import datetime as dt\n",
        "from dateutil import parser as dtparser\n",
        "\n",
        "import fsspec\n",
        "from urllib import request\n",
        "\n",
        "import echopype as ep\n",
        "import xarray as xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba34828a",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_type='Hake'\n",
        "range_meter_bin = 0.2\n",
        "ping_time_bin = '2s'\n",
        "start_datetime = dt.datetime(2017, 7, 24, 0, 0)\n",
        "end_datetime = dt.datetime(2017, 8, 24, 23, 59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a820b07",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dpath = Path('./'+f\"{data_type}_range={range_meter_bin}_ping={ping_time_bin}_start={start_datetime.strftime('%Y-%m-%d-%H-%M')}_end={end_datetime.strftime('%Y-%m-%d-%H-%M')}\"\n",
        ")\n",
        "base_dpath.mkdir(exist_ok=True)\n",
        "\n",
        "calibrated_dpath = (base_dpath / 'HakeSurvey')\n",
        "calibrated_dpath.mkdir(exist_ok=True)\n",
        "\n",
        "lon_dpath = (base_dpath / 'Lon')\n",
        "lon_dpath.mkdir(exist_ok=True)\n",
        "\n",
        "lat_dpath = (base_dpath / 'Lat')\n",
        "lat_dpath.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f019dd8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "fs = fsspec.filesystem('s3', anon=True)\n",
        "\n",
        "bucket = \"ncei-wcsd-archive\"\n",
        "rawdirpath = \"data/raw/Bell_M._Shimada/SH1707/EK60\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a595f70c",
      "metadata": {},
      "outputs": [],
      "source": [
        "s3rawfiles = fs.glob(f\"{bucket}/{rawdirpath}/*.raw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf12ba38",
      "metadata": {},
      "outputs": [],
      "source": [
        "date_list = []\n",
        "\n",
        "for x in range(0, (end_datetime-start_datetime).days + 1):\n",
        "    date = start_datetime + dt.timedelta(days = x)\n",
        "    date_list.append(str(date.month).zfill(2)+str(date.day).zfill(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3babd98",
      "metadata": {},
      "outputs": [],
      "source": [
        "s3rawfiles = [\n",
        "    s3path for s3path in s3rawfiles \n",
        "    if any([f\"D2017{datestr}\" in s3path for datestr in date_list])\n",
        "]\n",
        "\n",
        "print(f\"There are {len(s3rawfiles)} target raw files available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85e3483e",
      "metadata": {},
      "outputs": [],
      "source": [
        "for s3rawfpath in s3rawfiles:\n",
        "    raw_fpath = Path(s3rawfpath)\n",
        "    try:\n",
        "        # Access file directly from S3 to create a converted EchoData object in memory\n",
        "        ed = ep.open_raw(\n",
        "            f\"s3://{s3rawfpath}\",\n",
        "            sonar_model='EK60',\n",
        "            storage_options={'anon': True}\n",
        "        )\n",
        "        \n",
        "        \n",
        "        # Use the EchoData object \"ed\" to generate calibrated and\n",
        "        # computed MVBS files that will be saved to netcdf\n",
        "        ds_Sv = ep.calibrate.compute_Sv(ed)\n",
        "        \n",
        "        ds_MVBS = ep.commongrid.compute_MVBS(\n",
        "            ds_Sv,\n",
        "            range_meter_bin=range_meter_bin,  # in meters\n",
        "            ping_time_bin=ping_time_bin  # in seconds\n",
        "        )\n",
        "        \n",
        "        ds_MVBS.to_netcdf(calibrated_dpath / f\"MVBS_{raw_fpath.stem}.nc\")\n",
        "\n",
        "        ds_lon = ed['Platform'].longitude\n",
        "        \n",
        "        ds_lon.to_netcdf(lon_dpath / f\"MVBS_{raw_fpath.stem}.nc\")\n",
        "        \n",
        "        ds_lat = ed['Platform'].latitude\n",
        "        \n",
        "        ds_lat.to_netcdf(lat_dpath / f\"MVBS_{raw_fpath.stem}.nc\")\n",
        "        \n",
        "        print(f\"MVBS_{raw_fpath.stem}.nc created\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process raw file {raw_fpath.name}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0c56b7",
      "metadata": {},
      "source": [
        "## Combine MVBS with Geographic Coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1319bbba",
      "metadata": {},
      "outputs": [],
      "source": [
        "MVBS_ds = xr.open_mfdataset(\n",
        "    str(calibrated_dpath / 'MVBS_*.nc'), \n",
        "    data_vars='minimal', coords='minimal',\n",
        "    combine='by_coords'\n",
        ")\n",
        "\n",
        "longitude = xr.open_mfdataset(\n",
        "    str(lon_dpath / '*.nc'),\n",
        "    data_vars='minimal', coords='minimal',\n",
        "    combine='by_coords'\n",
        ")\n",
        "\n",
        "latitude = xr.open_mfdataset(\n",
        "    str(lat_dpath / '*.nc'),\n",
        "    data_vars='minimal', coords='minimal',\n",
        "    combine='by_coords'\n",
        ")\n",
        "\n",
        "lon = longitude[\"longitude\"]\n",
        "\n",
        "lat = latitude[\"latitude\"]\n",
        "\n",
        "lon=lon.interp(time1=MVBS_ds[\"ping_time\"])\n",
        "lat=lat.interp(time1=MVBS_ds[\"ping_time\"])\n",
        "\n",
        "MVBS_ds[\"longitude\"]=lon\n",
        "MVBS_ds[\"latitude\"]=lat\n",
        "\n",
        "import datetime\n",
        "history = (\n",
        "        f\"{datetime.datetime.utcnow()} +00:00. \"\n",
        "        \"Interpolated from Platform latitude/longitude.\"\n",
        "    )\n",
        "MVBS_ds[\"latitude\"] = MVBS_ds[\"latitude\"].assign_attrs({\"history\": history})\n",
        "MVBS_ds[\"longitude\"] = MVBS_ds[\"longitude\"].assign_attrs({\"history\": history})\n",
        "\n",
        "MVBS_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed81b817",
      "metadata": {},
      "outputs": [],
      "source": [
        "MVBS_ds.to_netcdf(base_dpath / \"concatenated_MVBS.nc\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "echoshader-d",
      "language": "python",
      "name": "echoshader-dev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
